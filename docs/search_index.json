[["modeling-aba.html", "16 The Area-Based Approach (ABA) to forest modelling 16.1 Read in data 16.2 ABA Processing", " 16 The Area-Based Approach (ABA) to forest modelling This section presents a complete workflow about processing ALS point cloud data to create wall-to-wall predictions of selected forest stand attributes using an area-based approach (ABA) to forest inventories. The steps used in this vignette as well as further details about enhanced forest inventories (EFI) are described in depth in White et al. 2013 and White et al. 2017. This vignette assumes that the user has a directory of classified and normalized .las/.laz files. First we load the package sf to work with spatial data. library(sf) 16.1 Read in data The function readLAScatalog() seen in section 14 builds a LAScatalog object from a folder. Make sure the ALS files have associated index files - for details see: Speed-up the computations on a LAScatalog. ctg &lt;- readLAScatalog(&quot;folder/&quot;) print(ctg) #&gt; class : LAScatalog #&gt; extent : 297317.5 , 316001 , 5089000 , 5099000 (xmin, xmax, ymin, ymax) #&gt; coord. ref. : +proj=utm +zone=18 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #&gt; area : 125.19 km² #&gt; points : 1.58 billion points #&gt; density : 12.6 points/m² #&gt; num. files : 138 plot(ctg) Now that our ALS data is prepared lets read in our inventory data using the st_read() function from the sf package. We read in a .shp file where each features is a point with a unique plot ID and corresponding plot level inventory summaries. plots &lt;- st_read(&quot;PRF_plots.shp&quot;) Our plots object contains 203 plots with coordinates of plot centers, plot name, and stand attributes: Lorey’s height (HL), Basal area (BA), and gross timber volume (GTV). plots #&gt; Simple feature collection with 203 features and 4 fields #&gt; geometry type: POINT #&gt; dimension: XY #&gt; bbox: xmin: 299051.3 ymin: 5089952 xmax: 314849.4 ymax: 5098426 #&gt; epsg (SRID): NA #&gt; proj4string: +proj=utm +zone=18 +ellps=GRS80 +units=m +no_defs #&gt; First 5 features: #&gt; PlotID HL BA GTV geometry #&gt; 1 PRF002 20.71166 38.21648 322.1351 POINT (313983.8 5094190) #&gt; 2 PRF003 19.46735 28.92692 251.1327 POINT (312218.6 5091995) #&gt; 3 PRF004 21.74877 45.16215 467.1033 POINT (311125.1 5092501) #&gt; 4 PRF005 27.76175 61.55561 783.9303 POINT (313425.2 5091836) #&gt; 5 PRF006 27.26387 39.78153 508.0337 POINT (313106.2 5091393) To visualize where the plots are in our study area we can overlay them on the LAScatalog. plot(ctg) plot(plots, add = TRUE, col = &quot;red&quot;) We have now prepared both our ALS and plot inventory data and can begin ABA processing. 16.2 ABA Processing 16.2.1 Step 1 - Clip ALS ground inventory The functions clip_* allow to extract regions of interest as seen in section 14. clip_roi() is capable of extraction from a shapefile. First we set opt_output_files() option to write the results on disc. This is an important option to set. The clipped plots will be saved on disk and not kept in memory. We also use the opt_filter() function to ignore noise below 0 m so that they do not influence future processing. We clip discs with a radius of 14.1 meters because our plot radius is 14.1 m. The plots_ALS_clipped object is now a LAScatalog object containing all clipped plots. opt_output_files(ctg) &lt;- paste0(tempdir(), &quot;/{PlotID}&quot;) # Write files to disc opt_filter(ctg) &lt;- &quot;-drop_z_below 0&quot; # Ignore points with elevations below 0 # Clip catalog object using plots with a circular buffer of 14.1 m plots_ALS_clipped &lt;- clip_roi(ctg, plots, radius=14.1) plots_ALS_clipped #&gt; class : LAScatalog #&gt; extent : 299037.3 , 314863.4 , 5089938 , 5098440 (xmin, xmax, ymin, ymax) #&gt; coord. ref. : +proj=utm +zone=18 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #&gt; area : 160376.5 m² #&gt; points : 1.67 million points #&gt; density : 10.4 points/m² #&gt; num. files : 203 16.2.2 Step 2 - Calculate plot metrics As seen in section 14 ground inventories are special cases of independent files. We first set some adequate processing options. We also use opt_output_files() &lt;- \"\" to have plot metrics stored in memory instead of on disc. opt_independent_files(plots_ALS_clipped) &lt;- TRUE opt_output_files(plots_ALS_clipped) &lt;- &quot;&quot; To calculate metrics for each plot we use the catalog_apply() functionality. We specify that we want to process our plots_ALS_clipped catalog object using cloud_metrics to calculate all metrics contained in the .stdmetrics_z function. The func argument also supports user defined functions. The output of catalog_apply() is a list of vectors (plots_metrics), which we convert into a data.table. plots_metrics &lt;- catalog_apply(plots_ALS_clipped, cloud_metrics, func = .stdmetrics_z) plots_metrics &lt;- data.table::rbindlist(plots_metrics) We have now calculated a variety of ALS metrics for each plot. In order to complete our inventory and begin modelling we now must merge ALS metrics with field measured values (D). D &lt;- cbind(as.data.frame(plots), plots_metrics) ### Step 3 - Modeling Here we provide a simple example of how to create an OLS model (`lm`) for Lorey&#39;s Mean Height (HL). Using the `summary` and `plot` functions we found that the 85^th^ percentile of height (`zq85`) for ALS metrics explain a large amount of variation in `HL` values. We are more than happy with this simple model. ```r m &lt;- lm(HL ~zq85, data=D) summary(m) #&gt; Call: #&gt; lm(formula = HL ~ zq85, data = D) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -4.640 -1.053 -0.031 1.030 4.258 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.29496 0.31116 7.376 4.2e-12 *** #&gt; zq85 0.93389 0.01525 61.237 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #&gt; #&gt; Residual standard error: 1.5 on 201 degrees of freedom #&gt; Multiple R-squared: 0.9491, Adjusted R-squared: 0.9489 #&gt; F-statistic: 3750 on 1 and 201 DF, p-value: &lt; 2.2e-16 Here we visualize the relationship between the observed (measured) and predicted (ALS-based) HL values. plot(D$HL, predict(m)) abline(0,1) 16.2.3 Step 4 - Wall to wall modelling Now that we have created a model using plot data, we now need to apply that model across our entire study area. To do so we first need to generate the same suite of ALS metrics (.stdmetrics_z) for our ALS data using the grid_metrics() function on our original collection of files. We have chosen to write these metrics into memory. Note that the res parameter is set to 25 because we want the resolution of our metrics to match the area of our sample plots (14.1 m radius = 625m2). opt_output_files(ctg) &lt;- &quot;&quot; metrics_w2w &lt;- grid_metrics(ctg, .stdmetrics_z, res = 25) To visualize any of the metrics you can use the plot function. plot(metrics_w2w$zq85) plot(metrics_w2w$zmean) plot(metrics_w2w$pzabovezmean) 16.2.4 Step 5 - Calculate wall-to-wall predictions We can use two methods for applying our model (m) to all of our ALS data. We can do this manually using the model coefficients, or use the predict function. Both of these methods produce the same output (HL_pred) which is a wall-to-wall raster of predicted Lorey’s mean height. HL_pred &lt;- coef(m)[1] + metrics_w2w$zq85 * coef(m)[2] # or HL_pred &lt;- predict(metrics_w2w$zq85, m) To visualize wall-to-wall predictions use plot(HL_pred) "]]
