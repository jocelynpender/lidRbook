```{r,echo=FALSE,message=FALSE,warning=FALSE}
r3dDefaults = rgl::r3dDefaults
rgl::setupKnitr()
r3dDefaults$FOV = 50
r3dDefaults$zoom = 0.5
library(lidR)
```
# Point based approach

Area-based approach (ABA) consists in computing metrics at the pixel level and tree-based apprach (TBA) consists in computing metrics at the tree level. Both are well known approches used in forestry to process point clouds. `lidR` provides tools to compute any user-defined metrics both in ABA, TBA as seen in previous sections. We have also seen that `lidR` extended the idea to voxel-based approach (VBA) but we also extended the metrics concept to the point-based apprach (PBA).

PBA consist in computing any user-defined metrics for each point using its neighborhood points. For each point the neibourhood can be either the k nearest neighbors or the points within a sphere centered on the processed point. The following section presents few applications made possible out of this tool. The function `point_metrics()` only takes care of mapping a user-defined function and the actual applications are not limited to the example below. It is up to the user to think out of the box.

## Roof segmentation

Roof are flat areas. [Limberger et al. (2015)](https://doi.org/10.1016/j.patcog.2014.12.020) described a method to find flat areas in a point clouds using an eigen values decomposition. Using the good user-defined function we can use `point_metrics()` to create this algorithm. In this example we will use the following urban scene:

```{r, rgl = TRUE}
las <- readLAS("data/chap11/building_WilliamsAZ_Urban_normalized.laz")
plot(las, size = 3)
```

First we need to defined a function that compute the eigen value decomposition of a set of points and estimate if the set of point is flat according to [Limberger et al. (2015)](https://doi.org/10.1016/j.patcog.2014.12.020) criteria.

```r
is.planar = function(x, y, z, th1 = 25, th2 = 6) {
  xyz <- cbind(x,y,z)
  cov_m <- cov(xyz)
  eigen_m <- eigen(cov_m)$value
  is_planar <- eigen_m[2] > (th1*eigen_m[3]) && (th2*eigen_m[2]) > eigen_m[1]
  return(list(planar = is_planar))
}
```

We then apply this function using 20 neighbors. We also use `filter = ~Classification != LASGROUND` to do not process points classified as ground. First the scene is normalized so by definition each ground point is expected to be part of a plan. Second this will speed-up a lot the computation because fewer points will be considered.

```r
M <- point_metrics(las, ~is.planar(X,Y,Z), k = 20, filter = ~Classification != LASGROUND)
```

We finally merge the output with the point cloud to visualize the result.

```r
las <- add_attribute(las, FALSE, "planar")
las$planar[M$pointID] <- M$planar
plot(las, color = "planar")
```

```{r, echo = FALSE, rgl = TRUE}
# here I'm cheating for the rendering the example above being too loog to compute
options(lidR.progress = FALSE)
las <- readLAS("data/chap11/building_WilliamsAZ_Urban_normalized.laz")
las <- lasdetectshape(las, shp_plane(k = 20), "planar", filter = ~Classification != LASGROUND)
plot(las, color = "planar", size = 3)
```

We can eventually set a valid classification to those points

```r
las$Classification[M$pointID] <- LASBUILDING
```

The function `is.planar()` is highly inneficient because `eigen()` is very slow. We can rewrite the eigen decomposition in C++ with `Rcpp` to make the function 10 times faster.

```r
Rcpp::sourceCpp(code = "
#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::export]]
arma::vec eigen_values(arma::mat A) {
arma::mat coeff, score;
arma::vec latent;
arma::princomp(coeff, score, latent, A);
return(latent);
}")

is.planar = function(x, y, z, th1 = 25, th2 = 6) {
  xyz <- cbind(x,y,z)
  eigen_m <- eigen_values(xyz)
  is_planar <- eigen_m[2] > (th1*eigen_m[3]) && (th2*eigen_m[2]) > eigen_m[1]
  return(list(planar = is_planar))
}
```

But yet `lidR` has a dedicated function for this specific task because we believe that it is of high interest to provide a specialized and thus faster version of this tool.

```r
las <- segment_shape(las, shp_plane(k = 25), "planar")
```

## Lake and wire segmentation

Eigen value decomposition applied with `point_metrics()` open multiple possibilities. For example by tweaking a bit the previous example we can design a lake segmentation algorithm.  A lake is a planar region with a vertical normal vector. To create a lake segmentation we simply need to add such constrain in `is.planar`. We can also design a wire segmentation algorithm. For a wire we can change the Limberger et al. (2015) constrains to enable the detection of elongated linear features instead of flat feature.

```{r}
is.linear = function(x, y, z, th = 10) {
  xyz <- cbind(x,y,z)
  eigen_m <- eigen_values(xyz)
  is_linear <-  th*eigen_m[3] < eigen_m[1] && th*eigen_m[2] < eigen_m[1]
  return(list(linear = is_linear))
}
```

```{r, echo = FALSE, rgl = TRUE}
las <- readLAS("data/chap11/wires.laz", filter = "-keep_random_fraction 0.3")
las <- lasdetectshape(las, shp_line(th1 = 8, k = 15), "linear", filter = ~Classification != LASGROUND)
plot(las, size = 5)
```

```{r, echo = FALSE, rgl = TRUE}
plot(las, color = "linear", size = 5)
```


```{r, echo = FALSE}
r3dDefaults$zoom = 0.7
```

again `lidR` has a dedicated function for this specific task because we believe that it is of high interest to provide a specialized and thus faster version of this tool.

```r
las <- segment_shape(las, shp_line(th = 8, k = 15), "linear")
```

## Multispectral coloring {#sec:pba-mscoloring}

`point_metrics()` is not limited to eigen value related metrics. It is only limited by user's imagination. In the following we will demonstrate how it an be used to attribute false color to a multispectral point cloud.

Multispectral ALS data are sampled with 3 devices each emmiting a different wavelength. The point cloud is usually provided in the form of 3 `las` files, each file corresponding to a spectral wavelength. No matter the actual wavelenght we can consider the first band as blue, the secod as red and the third one as green and thus consider that each point has a pure color.

```{r, rgl = TRUE, message=FALSE}
f1 = "data/chap11/PR1107_c1_ar_c.laz"
f2 = "data/chap11/PR1107_c2_ar_c.laz"
f3 = "data/chap11/PR1107_c3_ar_c.laz"
las <- readMSLAS(f1, f2, f3,  filter = "-keep_z_below 300")
plot(las, color = "ScannerChannel", size = 5)
```

We now want to attribute an RGB value to each point. A single point being sampled with a single 'color' we need to use its neighborhood to defined 3 bands. For each point we look in its neighborhood. In the neigboorhod some points are red some are blue and some are green. We average the intensities of each color and we consider these 3 values as the RGB color of the central point. Because some points are likely to have 0 red/blue/green neigbor we can set R G and B equal to `NA` for those points and later discard those points.


```{r}
set.color = function(intensity, channel)
{
  # Slit the intensities of each channel
  i1 = intensity[channel == 1]
  i2 = intensity[channel == 2]
  i3 = intensity[channel == 3]
  
  # If one channel is missing return RGB = NA
  if (length(i1) == 0 | length(i2) == 0 | length(i3) == 0)
    return(list(R = NA_integer_, G = NA_integer_, B = NA_integer_))
  
  # Average and normalise the intensities
  i1 = as.integer(mean(i1))
  i2 = as.integer(mean(i2))
  i3 = as.integer(mean(i3))
  if (i1 > 255L) i1 = 255L
  if (i2 > 255L) i2 = 255L
  if (i3 > 255L) i3 = 255L
  
  return(list(R = i1, G = i2, B = i3))
}
```

We can then apply this function with `point_metrics()` using a spherical neighborhood. The next steps being to attributes the output of `point_metrics()` back into the `LAS` object for a nice display.

```{r, rgl = TRUE}
M = point_metrics(las, ~set.color(Intensity, ScannerChannel), r = 0.5)
las@data$R <- M$R
las@data$G <- M$G
las@data$B <- M$B
colored <- filter_poi(las, !is.na(R)) # remove RGB = NA
plot(colored, color = "RGB", nbits = 8, size = 3)
```

This method is a bit naive 'as is'. First the intensities returned by each channel are not comparable and required to be normalized first. We could also argue about the choice of discareding RGB = `NA`. Instead we could have chosen to set a pure color. To finish enforcing a maximum value to 255 works in this specific example because very few intensity values are actually above 255 but is meaningless in general case. Anyway this is only a demo to show how to think out of the box with `point_metrics()`.


